import json
from typing import List, Dict, Optional, Tuple, Any

from openai import OpenAI

from config import (
    OPENAI_API_KEY,
    OPENAI_API_BASE,
    MODEL_NAME,
    TOP_K,
    DEFAULT_RETRIEVAL_STRATEGY, 
    ENABLE_ADVANCED_RAG,
)
from vector_store import VectorStore
from tools import tool_manager


class RAGAgent:
    def __init__(
        self,
        model: str = MODEL_NAME,
    ):
        self.model = model

        self.client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_API_BASE)

        self.vector_store = VectorStore()
        
        # ã€æ–°å¢ã€‘ä¿å­˜é«˜çº§ç­–ç•¥å¼€å…³çŠ¶æ€
        self.enable_advanced_rag = ENABLE_ADVANCED_RAG 

        self.system_prompt = """ä½ æ˜¯ä¸€ä½å‹å¥½ã€ä¸¥è°¨ä¸”ä¸“ä¸šçš„æ™ºèƒ½è¯¾ç¨‹åŠ©æ•™ã€‚
        ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æä¾›çš„ã€è¯¾ç¨‹å†…å®¹ã€‘æ¥å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚

        **å›ç­”ç­–ç•¥ï¼ˆä¼˜å…ˆçº§é¡ºåºï¼‰ï¼š**
        1. **ä¼˜å…ˆä½¿ç”¨è¯¾ç¨‹å†…å®¹**ï¼šé¦–å…ˆåŸºäºã€è¯¾ç¨‹å†…å®¹ã€‘ä¸­çš„ä¿¡æ¯å›ç­”é—®é¢˜
        2. **è¡¥å……è”ç½‘æœç´¢**ï¼šå¦‚æœã€è¯¾ç¨‹å†…å®¹ã€‘ä¿¡æ¯ä¸è¶³æˆ–æ²¡æœ‰ç›¸å…³å†…å®¹ï¼Œæ‰ä½¿ç”¨è”ç½‘æœç´¢è·å–è¡¥å……ä¿¡æ¯
        3. **ç›´æ¥å›ç­”**ï¼šå¯¹äºä¸æ¶‰åŠè¯¾ç¨‹çŸ¥è¯†çš„ä¸€èˆ¬æ€§é—®é¢˜ï¼ˆå¦‚æ—¶é—´ã€ç®€å•è®¡ç®—ï¼‰ï¼Œç›´æ¥å›ç­”æ— éœ€è¿½æº¯æ¥æº

        å›ç­”è¦æ±‚ï¼š
        1. **åŸºäºäº‹å®**ï¼šæ‰€æœ‰å›ç­”å¿…é¡»ä¸¥æ ¼åŸºäºã€è¯¾ç¨‹å†…å®¹ã€‘æˆ–è€…è”ç½‘æœç´¢ä¸­æ£€ç´¢åˆ°çš„ä¿¡æ¯ã€‚
        2. **è¿½æº¯æ¥æº**ï¼šåœ¨å›ç­”ä¸­ä½¿ç”¨è¯¾ç¨‹å†…å®¹æ—¶ï¼Œå¿…é¡»åœ¨å¼€å¤´æˆ–æœ«å°¾æ ‡æ³¨ä¿¡æ¯æ¥æºï¼Œæ ¼å¼ä¸ºï¼š[æ¥æºï¼šæ–‡ä»¶åï¼Œé¡µç  X æˆ– å¹»ç¯ç‰‡ X] æˆ– [æ¥æºï¼šæ–‡ä»¶å]ï¼ˆè‹¥æ— é¡µç ï¼‰ã€‚å¦‚æœä½¿ç”¨äº†è”ç½‘æœç´¢ï¼Œæ ‡æ³¨ä¸ºï¼š[æ¥æºï¼šç½‘ç»œæœç´¢ç»“æœ]ã€‚å¦‚æœæœ‰å¤šä¸ªæ¥æºï¼Œè¯·åˆå¹¶æˆ–åˆ†åˆ«æ ‡æ³¨ã€‚
        3. **æ— æ³•å›ç­”**ï¼šå¦‚æœã€è¯¾ç¨‹å†…å®¹ã€‘å’Œè”ç½‘æœç´¢ä¸­éƒ½æ‰¾ä¸åˆ°è¶³å¤Ÿçš„ä¿¡æ¯æ¥å›ç­”å­¦ç”Ÿçš„é—®é¢˜ï¼Œè¯·å‘ŠçŸ¥å­¦ç”Ÿï¼š"æˆ‘æ— æ³•æ ¹æ®å½“å‰è¯¾ç¨‹ææ–™å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œè¯·å‚è€ƒç›¸å…³æ•™ææˆ–è”ç³»è€å¸ˆã€‚"
        4. **è¯­æ°”ä¸“ä¸š**ï¼šä¿æŒåŠ©æ•™çš„ä¸“ä¸šã€å‹å¥½å’Œæ¡ç†æ¸…æ™°çš„è¯­æ°”ã€‚
        """

    def _construct_search_query(self, current_query: str, chat_history: Optional[List[Dict]] = None) -> str:
        """
        ä½¿ç”¨å¯¹è¯å†å²æ¥æç‚¼æœç´¢å…³é”®è¯ï¼Œæå‡å¤šè½®æ£€ç´¢ç²¾åº¦ã€‚
        ã€é€»è¾‘ä¿®æ”¹ã€‘ä»…åœ¨ self.enable_advanced_rag å¼€å¯æ—¶ï¼Œæ‰æ‰§è¡Œå¤šè½®å¢å¼ºã€‚
        """
        if not self.enable_advanced_rag:
            return current_query
            
        if not chat_history or len(chat_history) < 2:
            return current_query
        
        # æå–æœ€è¿‘çš„å¯¹è¯ï¼ˆä¾‹å¦‚ï¼Œæœ€è¿‘çš„é—®ç­”å¯¹ï¼‰
        last_exchange = chat_history[-2:]
        
        # æ„é€ ç”¨äº RAG æ£€ç´¢çš„æœ€ç»ˆæŸ¥è¯¢
        recent_context = f"æœ€è¿‘çš„é—®é¢˜ï¼š{last_exchange[0]['content']}ï¼Œæœ€è¿‘çš„å›ç­”ï¼š{last_exchange[1]['content']}ã€‚"
        return f"{recent_context} å­¦ç”Ÿçš„æ–°é—®é¢˜æ˜¯ï¼š{current_query}"

    def _analyze_query_type(self, query: str) -> str:
        """
        ä½¿ç”¨ LLM åˆ†ææŸ¥è¯¢æ„å›¾å’Œç±»å‹ï¼Œä»¥å†³å®šæœ€ä½³æ£€ç´¢ç­–ç•¥ã€‚
        """
        prompt = f"""åˆ†æä»¥ä¸‹ç”¨æˆ·æŸ¥è¯¢çš„ç±»å‹å’Œæ„å›¾ï¼Œå¹¶ä¸¥æ ¼ä»¥å•å­—å­—ç¬¦ä¸²å½¢å¼è¿”å›æœ€é€‚åˆçš„æ£€ç´¢ç­–ç•¥ã€‚

        1. 'HYBRID': å¦‚æœæŸ¥è¯¢æ˜¯æ¨¡ç³Šçš„ã€ä½¿ç”¨äº†ä»£è¯ï¼ˆå¦‚â€œå®ƒâ€ã€â€œè¿™ä¸ªâ€ï¼‰æˆ–åŒæ—¶åŒ…å«å…³é”®è¯å’Œæ¦‚å¿µï¼Œéœ€è¦å¹³è¡¡è¯­ä¹‰å’Œç²¾ç¡®åŒ¹é…ã€‚
        2. 'BM25': å¦‚æœæŸ¥è¯¢åŒ…å«å¤§é‡ç‰¹å®šã€ç½•è§ã€æŠ€æœ¯æ€§åè¯æˆ–IDï¼Œä¸”æ˜æ˜¾æ˜¯ä¸€ä¸ªå…¨æ–°çš„ã€ç²¾ç¡®åŒ¹é…çš„é—®é¢˜ã€‚
        3. 'DENSE': å¦‚æœæŸ¥è¯¢æ˜¯å…³äºå®šä¹‰ã€å…³ç³»ã€æ¯”è¾ƒæˆ–å¹¿ä¹‰ä¸»é¢˜ï¼Œéœ€è¦æ·±åº¦è¯­ä¹‰ç†è§£ã€‚

        æŸ¥è¯¢: "{query}"

        ä»…è¿”å›ä»¥ä¸‹å­—ç¬¦ä¸²ä¹‹ä¸€: 'HYBRID', 'BM25', 'DENSE'
        """
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.0,
                max_tokens=10
            )
            # æ¸…ç†å’Œè§„èŒƒåŒ–è¾“å‡º
            return response.choices[0].message.content.strip().upper().replace('"', '')
        except Exception:
            # å¤±è´¥æ—¶é»˜è®¤ä½¿ç”¨ config ä¸­çš„ç­–ç•¥
            return DEFAULT_RETRIEVAL_STRATEGY

    def retrieve_context(
        self, query: str, chat_history: Optional[List[Dict]] = None, top_k: int = TOP_K
    ) -> Tuple[str, List[Dict]]:
        """
        ã€æ ¸å¿ƒä¿®æ”¹ã€‘å®ç°æ£€ç´¢ç­–ç•¥åˆ†æ´¾å™¨ (Strategy Dispatcher)ã€‚
        æ–°å¢é€»è¾‘ï¼šå¦‚æœ self.enable_advanced_rag ä¸º Falseï¼Œåˆ™å¼ºåˆ¶ä½¿ç”¨ DENSE ç­–ç•¥ã€‚
        """
        # 1. æ„é€ ç”¨äºæ£€ç´¢çš„å¢å¼ºæŸ¥è¯¢ (è¯¥å‡½æ•°å†…éƒ¨ä¼šæ ¹æ®å¼€å…³è¿”å›åŸå§‹æˆ–å¢å¼ºæŸ¥è¯¢)
        search_query = self._construct_search_query(query, chat_history)

        retrieved_docs = []
        
        # --- ç­–ç•¥å†³ç­–å¼€å§‹ ---
        if not self.enable_advanced_rag:
            # ã€é€€åŒ–é€»è¾‘ã€‘å¦‚æœé«˜çº§RAGå¼€å…³å…³é—­ï¼Œå¼ºåˆ¶é€€åŒ–åˆ°çº¯å‘é‡ï¼ˆDENSEï¼‰ç­–ç•¥ã€‚
            query_type = "DENSE"
            print("âš™ï¸ é«˜çº§RAGå¢å¼ºå·²å…³é—­ï¼Œå¼ºåˆ¶é€€åŒ–åˆ°çº¯å‘é‡å¯†é›†æ£€ç´¢ (DENSE) ç­–ç•¥ã€‚")
            
        else:
            # å¯ç”¨é«˜çº§ç­–ç•¥ï¼šæ‰§è¡Œ LLM ç­–ç•¥åˆ†æ
            query_type = self._analyze_query_type(search_query)
            print(f"âš™ï¸ é«˜çº§RAGå¢å¼ºå·²å¯ç”¨ | LLMåˆ†æç­–ç•¥: {query_type}")

        # 3. ç­–ç•¥åˆ†æ´¾å™¨ (Dispatching logic based on query_type)
        if query_type == 'DENSE':
            # æ¦‚å¿µä¸»å¯¼æˆ–é€€åŒ–ç­–ç•¥ï¼šçº¯å‘é‡æ£€ç´¢
            retrieved_docs = self.vector_store.search_dense(search_query, top_k=top_k)
            print("â¡ï¸ é‡‡ç”¨çº¯å‘é‡å¯†é›†æ£€ç´¢ (search_dense)")
            
        elif query_type == 'BM25':
            # å…³é”®è¯ä¸»å¯¼ï¼šçº¯ç¨€ç–æ£€ç´¢
            retrieved_docs = self.vector_store.search_bm25(search_query, top_k=top_k)
            print("â¡ï¸ é‡‡ç”¨çº¯ BM25 ç¨€ç–æ£€ç´¢ (search_bm25)")

        elif query_type == 'HYBRID': 
            # æ··åˆæ£€ç´¢
            retrieved_docs = self.vector_store.search(search_query, top_k=top_k)
            print("â¡ï¸ é‡‡ç”¨ RRF æ··åˆæ£€ç´¢ (search)")
        
        else:
            # LLMåˆ†æå¤±è´¥æ—¶çš„å…œåº•ç­–ç•¥ (ä»…åœ¨é«˜çº§æ¨¡å¼ä¸‹å¯èƒ½å‘ç”Ÿ)
            # ä½¿ç”¨ config ä¸­é…ç½®çš„ DEFAULT_RETRIEVAL_STRATEGY
            if DEFAULT_RETRIEVAL_STRATEGY == "BM25":
                 retrieved_docs = self.vector_store.search_bm25(search_query, top_k=top_k)
            elif DEFAULT_RETRIEVAL_STRATEGY == "DENSE":
                 retrieved_docs = self.vector_store.search_dense(search_query, top_k=top_k)
            else:
                 retrieved_docs = self.vector_store.search(search_query, top_k=top_k)
            print(f"âš ï¸ LLM åˆ†æå¤±è´¥ï¼Œå›é€€åˆ° DEFAULT ç­–ç•¥: {DEFAULT_RETRIEVAL_STRATEGY}")
            
        # --- ç­–ç•¥å†³ç­–ç»“æŸ ---

        # 4. æ ¼å¼åŒ–æ£€ç´¢ç»“æœï¼Œæ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        context_parts = []
        
        for doc in retrieved_docs:
            content = doc["content"]
            metadata = doc["metadata"]
            
            filename = metadata.get("filename", "æœªçŸ¥æ–‡ä»¶")
            page_number = metadata.get("page_number", 0)
            
            # 5. æ¯ä¸ªæ£€ç´¢ç»“æœéœ€è¦åŒ…å«æ¥æºä¿¡æ¯ï¼ˆæ–‡ä»¶åå’Œé¡µç ï¼‰
            if page_number and page_number > 0:
                # åˆ¤æ–­æ˜¯é¡µç  (PDF) è¿˜æ˜¯å¹»ç¯ç‰‡ (PPTX)
                source_label = "é¡µç " if metadata.get("filetype") == ".pdf" else "å¹»ç¯ç‰‡"
                source_info = f"[æ¥æºï¼š{filename}, {source_label} {page_number}]"
            else:
                # DOCX/TXT æˆ–æ²¡æœ‰é¡µç /å¹»ç¯ç‰‡ä¿¡æ¯çš„æ–‡æ¡£
                source_info = f"[æ¥æºï¼š{filename}]"
                
            # å°†æ¥æºä¿¡æ¯æ”¾åœ¨å†…å®¹ä¸Šæ–¹ï¼Œç”¨äº LLM åŒºåˆ†
            context_parts.append(f"{source_info}\n{content}\n---")

        context_string = "\n".join(context_parts)
        
        # 6. è¿”å›æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²å’ŒåŸå§‹æ£€ç´¢ç»“æœåˆ—è¡¨
        return context_string, retrieved_docs

    def generate_response(
        self,
        query: str,
        context: str,
        chat_history: Optional[List[Dict]] = None,
    ) -> str:
        """ç”Ÿæˆå›ç­”"""
        messages = [{"role": "system", "content": self.system_prompt}]

        if chat_history:
            messages.extend(chat_history)

        user_text = f"""
        è¯·åŸºäºä¸‹é¢çš„ã€è¯¾ç¨‹å†…å®¹ã€‘æ¥å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚è¯·ä¸¥æ ¼éµå¾ªç³»ç»Ÿæç¤ºè¯ä¸­çš„æ‰€æœ‰è¦æ±‚ã€‚

        **ä¼˜å…ˆçº§ç­–ç•¥ï¼š**
        1. é¦–å…ˆåŸºäºã€è¯¾ç¨‹å†…å®¹ã€‘å›ç­”é—®é¢˜
        2. åªæœ‰åœ¨ã€è¯¾ç¨‹å†…å®¹ã€‘ä¿¡æ¯ä¸è¶³æ—¶ï¼Œæ‰ä½¿ç”¨å·¥å…·è·å–è¡¥å……ä¿¡æ¯

        ã€è¯¾ç¨‹å†…å®¹ã€‘
        {context}

        ã€å­¦ç”Ÿé—®é¢˜ã€‘
        {query}

        å¦‚æœã€è¯¾ç¨‹å†…å®¹ã€‘æ— æ³•æä¾›è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œä½ å¯ä»¥é€‰æ‹©ä½¿ç”¨æä¾›çš„å·¥å…·æœç´¢ç½‘ç»œä¿¡æ¯ã€è¿›è¡Œè®¡ç®—æˆ–è·å–å½“å‰æ—¶é—´ã€‚
        """

        messages.append({"role": "user", "content": user_text})
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                tools=tool_manager.get_tool_definitions(),
                tool_choice="auto",
                temperature=0.7,
                max_tokens=1500
            )

            response_message = response.choices[0].message

            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if response_message.tool_calls:
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                tool_results = self._execute_tool_calls(response_message.tool_calls)

                # å°†å·¥å…·è°ƒç”¨ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
                messages.append(response_message)
                for tool_result in tool_results:
                    messages.append(tool_result)

                # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šåŸºäºå·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›ç­”
                final_response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=0.7,
                    max_tokens=1500
                )

                return final_response.choices[0].message.content
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›ç»“æœ
                return response_message.content

        except Exception as e:
            return f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {str(e)}"

    def _execute_tool_calls(self, tool_calls) -> List[Dict]:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶è¿”å›ç»“æœ"""
        tool_results = []

        for tool_call in tool_calls:
            tool_name = tool_call.function.name
            tool_args = json.loads(tool_call.function.arguments)

            print(f"ğŸ”§ æ‰§è¡Œå·¥å…·: {tool_name} å‚æ•°: {tool_args}")

            # æ‰§è¡Œå·¥å…·
            tool_result = tool_manager.execute_tool(tool_name, tool_args)

            # æ ¼å¼åŒ–å·¥å…·ç»“æœæ¶ˆæ¯
            tool_result_message = {
                "role": "tool",
                "tool_call_id": tool_call.id,
                "content": tool_result
            }

            tool_results.append(tool_result_message)

        return tool_results

    def answer_question(
        self, query: str, chat_history: Optional[List[Dict]] = None, top_k: int = TOP_K
    ) -> str:
        """å›ç­”é—®é¢˜"""
        
        # å°† chat_history ä¼ å…¥ retrieve_contextï¼Œå®ç°å¤šè½®æ£€ç´¢å¢å¼ºå’Œç­–ç•¥åˆ†æ´¾
        context, retrieved_docs = self.retrieve_context(query, chat_history=chat_history, top_k=top_k)

        if not context:
            context = "ï¼ˆæœªæ£€ç´¢åˆ°ç‰¹åˆ«ç›¸å…³çš„è¯¾ç¨‹ææ–™ï¼‰"

        answer = self.generate_response(query, context, chat_history)

        return answer

    def chat(self) -> None:
        """äº¤äº’å¼å¯¹è¯"""
        print("=" * 60)
        print("æ¬¢è¿ä½¿ç”¨æ™ºèƒ½è¯¾ç¨‹åŠ©æ•™ç³»ç»Ÿï¼")
        print("å½“å‰ RAG ç­–ç•¥æ¨¡å¼:", "é«˜çº§å¢å¼ºæ¨¡å¼" if self.enable_advanced_rag else "çº¯å‘é‡åŸºçº¿æ¨¡å¼ (DENSE)")
        print("=" * 60)

        chat_history = []

        while True:
            try:
                query = input("\nå­¦ç”Ÿ: ").strip()

                if not query:
                    continue

                answer = self.answer_question(query, chat_history=chat_history)

                print(f"\nåŠ©æ•™: {answer}")

                # æ›´æ–°å¯¹è¯å†å²
                chat_history.append({"role": "user", "content": query})
                chat_history.append({"role": "assistant", "content": answer})

            except Exception as e:
                print(f"\né”™è¯¯: {str(e)}")