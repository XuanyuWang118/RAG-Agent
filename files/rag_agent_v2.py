import json
from typing import List, Dict, Optional, Tuple

from openai import OpenAI

from config import (
    OPENAI_API_KEY,
    OPENAI_API_BASE,
    MODEL_NAME,
    TOP_K,
)
from vector_store import VectorStore
from tools import tool_manager


class RAGAgent:
    def __init__(
        self,
        model: str = MODEL_NAME,
    ):
        self.model = model

        self.client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_API_BASE)

        self.vector_store = VectorStore()

        """
        TODO: å®ç°å¹¶è°ƒæ•´ç³»ç»Ÿæç¤ºè¯ï¼Œä½¿å…¶ç¬¦åˆè¯¾ç¨‹åŠ©æ•™çš„è§’è‰²å’Œå›ç­”ç­–ç•¥
        """
        self.system_prompt = """ä½ æ˜¯ä¸€ä½å‹å¥½ã€ä¸¥è°¨ä¸”ä¸“ä¸šçš„æ™ºèƒ½è¯¾ç¨‹åŠ©æ•™ã€‚
        ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æä¾›çš„ã€è¯¾ç¨‹å†…å®¹ã€‘æ¥å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚

        **å›ç­”ç­–ç•¥ï¼ˆä¼˜å…ˆçº§é¡ºåºï¼‰ï¼š**
        1. **ä¼˜å…ˆä½¿ç”¨è¯¾ç¨‹å†…å®¹**ï¼šé¦–å…ˆåŸºäºã€è¯¾ç¨‹å†…å®¹ã€‘ä¸­çš„ä¿¡æ¯å›ç­”é—®é¢˜
        2. **è¡¥å……è”ç½‘æœç´¢**ï¼šå¦‚æœã€è¯¾ç¨‹å†…å®¹ã€‘ä¿¡æ¯ä¸è¶³æˆ–æ²¡æœ‰ç›¸å…³å†…å®¹ï¼Œæ‰ä½¿ç”¨è”ç½‘æœç´¢è·å–è¡¥å……ä¿¡æ¯
        3. **ç›´æ¥å›ç­”**ï¼šå¯¹äºä¸æ¶‰åŠè¯¾ç¨‹çŸ¥è¯†çš„ä¸€èˆ¬æ€§é—®é¢˜ï¼ˆå¦‚æ—¶é—´ã€ç®€å•è®¡ç®—ï¼‰ï¼Œç›´æ¥å›ç­”æ— éœ€è¿½æº¯æ¥æº

        å›ç­”è¦æ±‚ï¼š
        1. **åŸºäºäº‹å®**ï¼šæ‰€æœ‰å›ç­”å¿…é¡»ä¸¥æ ¼åŸºäºã€è¯¾ç¨‹å†…å®¹ã€‘æˆ–è€…è”ç½‘æœç´¢ä¸­æ£€ç´¢åˆ°çš„ä¿¡æ¯ã€‚
        2. **è¿½æº¯æ¥æº**ï¼šåœ¨å›ç­”ä¸­ä½¿ç”¨è¯¾ç¨‹å†…å®¹æ—¶ï¼Œå¿…é¡»åœ¨å¼€å¤´æˆ–æœ«å°¾æ ‡æ³¨ä¿¡æ¯æ¥æºï¼Œæ ¼å¼ä¸ºï¼š[æ¥æºï¼šæ–‡ä»¶åï¼Œé¡µç  X æˆ– å¹»ç¯ç‰‡ X] æˆ– [æ¥æºï¼šæ–‡ä»¶å]ï¼ˆè‹¥æ— é¡µç ï¼‰ã€‚å¦‚æœä½¿ç”¨äº†è”ç½‘æœç´¢ï¼Œæ ‡æ³¨ä¸ºï¼š[æ¥æºï¼šç½‘ç»œæœç´¢ç»“æœ]ã€‚å¦‚æœæœ‰å¤šä¸ªæ¥æºï¼Œè¯·åˆå¹¶æˆ–åˆ†åˆ«æ ‡æ³¨ã€‚
        3. **æ— æ³•å›ç­”**ï¼šå¦‚æœã€è¯¾ç¨‹å†…å®¹ã€‘å’Œè”ç½‘æœç´¢ä¸­éƒ½æ‰¾ä¸åˆ°è¶³å¤Ÿçš„ä¿¡æ¯æ¥å›ç­”å­¦ç”Ÿçš„é—®é¢˜ï¼Œè¯·å‘ŠçŸ¥å­¦ç”Ÿï¼š"æˆ‘æ— æ³•æ ¹æ®å½“å‰è¯¾ç¨‹ææ–™å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œè¯·å‚è€ƒç›¸å…³æ•™ææˆ–è”ç³»è€å¸ˆã€‚"
        4. **è¯­æ°”ä¸“ä¸š**ï¼šä¿æŒåŠ©æ•™çš„ä¸“ä¸šã€å‹å¥½å’Œæ¡ç†æ¸…æ™°çš„è¯­æ°”ã€‚
        """

    def retrieve_context(
        self, query: str, top_k: int = TOP_K
    ) -> Tuple[str, List[Dict]]:
        """æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡
        TODO: å®ç°æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡
        è¦æ±‚ï¼š
        1. ä½¿ç”¨å‘é‡æ•°æ®åº“æ£€ç´¢ç›¸å…³æ–‡æ¡£
        2. æ ¼å¼åŒ–æ£€ç´¢ç»“æœï¼Œæ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        3. æ¯ä¸ªæ£€ç´¢ç»“æœéœ€è¦åŒ…å«æ¥æºä¿¡æ¯ï¼ˆæ–‡ä»¶åå’Œé¡µç ï¼‰
        4. è¿”å›æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²å’ŒåŸå§‹æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        # 1. ä½¿ç”¨å‘é‡æ•°æ®åº“æ£€ç´¢ç›¸å…³æ–‡æ¡£
        retrieved_docs = self.vector_store.search(query, top_k=top_k)
        
        # 2. æ ¼å¼åŒ–æ£€ç´¢ç»“æœï¼Œæ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        context_parts = []
        
        # ä½¿ç”¨é›†åˆå»é‡ï¼Œé¿å…é‡å¤å¼•ç”¨ç›¸åŒçš„æ¥æº
        source_set = set()
        
        for doc in retrieved_docs:
            content = doc["content"]
            metadata = doc["metadata"]
            
            filename = metadata.get("filename", "æœªçŸ¥æ–‡ä»¶")
            page_number = metadata.get("page_number", 0)
            
            # 3. æ¯ä¸ªæ£€ç´¢ç»“æœéœ€è¦åŒ…å«æ¥æºä¿¡æ¯ï¼ˆæ–‡ä»¶åå’Œé¡µç ï¼‰
            if page_number and page_number > 0:
                # åˆ¤æ–­æ˜¯é¡µç  (PDF) è¿˜æ˜¯å¹»ç¯ç‰‡ (PPTX)
                source_label = "é¡µç " if metadata.get("filetype") == ".pdf" else "å¹»ç¯ç‰‡"
                source_info = f"[æ¥æºï¼š{filename}, {source_label} {page_number}]"
                source_set.add(f"{filename}, {source_label} {page_number}")
            else:
                # DOCX/TXT æˆ–æ²¡æœ‰é¡µç /å¹»ç¯ç‰‡ä¿¡æ¯çš„æ–‡æ¡£
                source_info = f"[æ¥æºï¼š{filename}]"
                source_set.add(filename)
                
            # å°†æ¥æºä¿¡æ¯æ”¾åœ¨å†…å®¹ä¸Šæ–¹ï¼Œç”¨äº LLM åŒºåˆ†
            context_parts.append(f"{source_info}\n{content}\n---")

        context_string = "\n".join(context_parts)
        
        # 4. è¿”å›æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²å’ŒåŸå§‹æ£€ç´¢ç»“æœåˆ—è¡¨
        return context_string, retrieved_docs

    def generate_response(
        self,
        query: str,
        context: str,
        chat_history: Optional[List[Dict]] = None,
    ) -> str:
        """ç”Ÿæˆå›ç­”
        
        å‚æ•°:
            query: ç”¨æˆ·é—®é¢˜
            context: æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
            chat_history: å¯¹è¯å†å²
        """
        messages = [{"role": "system", "content": self.system_prompt}]

        if chat_history:
            messages.extend(chat_history)

        """
        TODO: å®ç°ç”¨æˆ·æç¤ºè¯
        è¦æ±‚ï¼š
        1. åŒ…å«ç›¸å…³çš„è¯¾ç¨‹å†…å®¹
        2. åŒ…å«å­¦ç”Ÿé—®é¢˜
        3. åŒ…å«æ¥æºä¿¡æ¯ï¼ˆæ–‡ä»¶åå’Œé¡µç ï¼‰
        4. è¿”å›ç”¨æˆ·æç¤ºè¯
        """
        user_text = f"""
        è¯·åŸºäºä¸‹é¢çš„ã€è¯¾ç¨‹å†…å®¹ã€‘æ¥å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚è¯·ä¸¥æ ¼éµå¾ªç³»ç»Ÿæç¤ºè¯ä¸­çš„æ‰€æœ‰è¦æ±‚ã€‚

        **ä¼˜å…ˆçº§ç­–ç•¥ï¼š**
        1. é¦–å…ˆåŸºäºã€è¯¾ç¨‹å†…å®¹ã€‘å›ç­”é—®é¢˜
        2. åªæœ‰åœ¨ã€è¯¾ç¨‹å†…å®¹ã€‘ä¿¡æ¯ä¸è¶³æ—¶ï¼Œæ‰ä½¿ç”¨å·¥å…·è·å–è¡¥å……ä¿¡æ¯

        ã€è¯¾ç¨‹å†…å®¹ã€‘
        {context}

        ã€å­¦ç”Ÿé—®é¢˜ã€‘
        {query}

        å¦‚æœã€è¯¾ç¨‹å†…å®¹ã€‘æ— æ³•æä¾›è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œä½ å¯ä»¥é€‰æ‹©ä½¿ç”¨æä¾›çš„å·¥å…·æœç´¢ç½‘ç»œä¿¡æ¯ã€è¿›è¡Œè®¡ç®—æˆ–è·å–å½“å‰æ—¶é—´ã€‚
        """

        messages.append({"role": "user", "content": user_text})
        
        # å¤šæ¨¡æ€æ¥å£ç¤ºæ„ï¼ˆå¦‚éœ€æ·»åŠ å›¾ç‰‡æ”¯æŒï¼Œå¯å‚è€ƒä»¥ä¸‹æ ¼å¼ï¼‰ï¼š
        # content_parts = [{"type": "text", "text": user_text}]
        # content_parts.append({
        #     "type": "image_url",
        #     "image_url": {"url": f"data:image/png;base64,{base64_image}"}
        # })
        # messages.append({"role": "user", "content": content_parts})

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                tools=tool_manager.get_tool_definitions(),
                tool_choice="auto",  # è®©AIè‡ªåŠ¨å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·
                temperature=0.7,
                max_tokens=1500
            )

            response_message = response.choices[0].message

            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if response_message.tool_calls:
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                tool_results = self._execute_tool_calls(response_message.tool_calls)

                # å°†å·¥å…·è°ƒç”¨ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
                messages.append(response_message)
                for tool_result in tool_results:
                    messages.append(tool_result)

                # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šåŸºäºå·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›ç­”
                final_response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=0.7,
                    max_tokens=1500
                )

                return final_response.choices[0].message.content
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›ç»“æœ
                return response_message.content

        except Exception as e:
            return f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {str(e)}"

    def _execute_tool_calls(self, tool_calls) -> List[Dict]:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶è¿”å›ç»“æœ"""
        tool_results = []

        for tool_call in tool_calls:
            tool_name = tool_call.function.name
            tool_args = json.loads(tool_call.function.arguments)

            print(f"ğŸ”§ æ‰§è¡Œå·¥å…·: {tool_name} å‚æ•°: {tool_args}")

            # æ‰§è¡Œå·¥å…·
            tool_result = tool_manager.execute_tool(tool_name, tool_args)

            # æ ¼å¼åŒ–å·¥å…·ç»“æœæ¶ˆæ¯
            tool_result_message = {
                "role": "tool",
                "tool_call_id": tool_call.id,
                "content": tool_result
            }

            tool_results.append(tool_result_message)

        return tool_results

    def answer_question(
        self, query: str, chat_history: Optional[List[Dict]] = None, top_k: int = TOP_K
    ) -> Dict[str, any]:
        """å›ç­”é—®é¢˜
        
        å‚æ•°:
            query: ç”¨æˆ·é—®é¢˜
            chat_history: å¯¹è¯å†å²
            top_k: æ£€ç´¢æ–‡æ¡£æ•°é‡
            
        è¿”å›:
            ç”Ÿæˆçš„å›ç­”
        """
        context, retrieved_docs = self.retrieve_context(query, top_k=top_k)

        if not context:
            context = "ï¼ˆæœªæ£€ç´¢åˆ°ç‰¹åˆ«ç›¸å…³çš„è¯¾ç¨‹ææ–™ï¼‰"

        answer = self.generate_response(query, context, chat_history)

        return answer

    def chat(self) -> None:
        """äº¤äº’å¼å¯¹è¯"""
        print("=" * 60)
        print("æ¬¢è¿ä½¿ç”¨æ™ºèƒ½è¯¾ç¨‹åŠ©æ•™ç³»ç»Ÿï¼")
        print("=" * 60)

        chat_history = []

        while True:
            try:
                query = input("\nå­¦ç”Ÿ: ").strip()

                if not query:
                    continue

                answer = self.answer_question(query, chat_history=chat_history)

                print(f"\nåŠ©æ•™: {answer}")

                chat_history.append({"role": "user", "content": query})
                chat_history.append({"role": "assistant", "content": answer})

            except Exception as e:
                print(f"\né”™è¯¯: {str(e)}")
