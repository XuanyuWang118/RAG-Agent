# 🎓 RAG-Agent

基于检索增强生成（RAG）的多模态智能课程问答系统，支持文档分析、图片理解、联网搜索和智能出题功能。

## 📋 项目简介

这是一个面向NLP课程的智能助教系统，集成了先进的检索技术和多模态理解能力，能够基于课程资料准确回答学生问题，并提供丰富的教学辅助功能。

**项目成员**: XuanyuWang, RuiTao, BoruiZhang; Shanghai Jiao Tong University

## ✨ 核心功能

### 智能检索系统

- **混合检索策略**: 结合密集检索(Dense)和稀疏检索(BM25)，通过RRF算法智能融合
- **LLM驱动策略选择**: 自动分析查询类型，选择最优检索策略(DENSE/BM25/HYBRID)
- **多轮对话增强**: 解决上下文指代问题，提升对话连贯性

### 多模态理解

- **文档图像提取**: 自动从PDF/PPTX中提取并理解图片内容
- **图片智能问答**: 支持上传图片进行分析和问答
- **视觉-文本融合**: 将图像描述与文本内容结合，提供更全面的答案

### 智能工具调用

- **联网搜索**: 通过Tavily API获取最新网络信息
- **智能出题**: 自动生成选择题和判断题进行学习评估
- **学习报告**: 自动生成学习总结和知识点梳理
- **计算器工具**: 支持数学计算和时间查询

### 交互界面

- **现代化Web界面**: 基于Streamlit的直观聊天界面
- **对话历史持久化**: 自动保存和恢复多轮对话
- **多对话管理**: 支持同时管理多个独立对话会话
- **动态知识库**: 支持实时添加新文档和文本内容

## ⚙️ 项目结构

### 核心文件

#### 主应用文件

```
├── app.py                 # Streamlit Web应用主界面
│                          # ├── 现代化聊天界面设计
│                          # ├── 多对话会话管理
│                          # ├── 图片上传和预览功能
│                          # ├── 动态知识库扩展
│                          # ├── 对话历史持久化存储
│                          # └── 实时系统状态监控
│
├── rag_agent.py           # RAG智能代理核心逻辑
│                          # ├── 智能查询分析和策略选择
│                          # ├── 多轮对话上下文管理
│                          # ├── 工具调用协调和执行
│                          # ├── 答案生成和格式化
│                          # ├── 图片内容理解集成
│                          # └── 学习报告自动生成
│
├── tools.py               # 工具管理器和工具实现
│                          # ├── WebSearchTool: 联网搜索功能
│                          # ├── QuizGenerationTool: 智能出题系统
│                          # ├── CalculatorTool: 数学计算器
│                          # ├── CurrentTimeTool: 时间查询
│                          # └── ToolManager: 统一工具调度
│
├── vector_store.py        # 向量数据库和混合检索系统
│                          # ├── ChromaDB向量存储管理
│                          # ├── BM25稀疏检索实现
│                          # ├── Reciprocal Rank Fusion (RRF) 融合
│                          # ├── 智能检索策略选择
│                          # ├── 批量向量化处理
│                          # └── 索引持久化存储
│
├── config.py              # 系统配置管理
│                          # ├── API密钥和模型配置
│                          # ├── 检索参数和阈值设置
│                          # ├── 数据路径和存储配置
│                          # ├── 文本处理参数配置
│                          # └── RAG系统开关控制
```

#### 数据处理文件

```
├── process_data.py        # 数据预处理和向量化脚本
│                          # ├── 多格式文档批量加载
│                          # ├── 文本分块和预处理
│                          # ├── 向量化处理和存储
│                          # ├── 缓存机制优化性能
│                          # ├── 进度显示和错误处理
│                          # └── 数据完整性验证
│
├── document_loader.py     # 多格式文档加载器
│                          # ├── PDF文档解析(PyMuPDF)
│                          # ├── PPTX幻灯片处理
│                          # ├── Word文档读取
│                          # ├── 纯文本文件加载
│                          # ├── 图像提取和保存
│                          # └── 文档元数据提取
│
├── text_splitter.py       # 文本分块和多模态内容处理
│                          # ├── 智能文本分块策略
│                          # ├── 多模态内容融合
│                          # ├── 图像描述生成集成
│                          # ├── 分块大小和重叠控制
│                          # ├── 文档结构保持
│                          # └── 内容质量优化
│
├── image_processor.py     # 图像理解和描述生成
│                          # ├── Qwen-VL视觉模型集成
│                          # ├── 图像内容分析
│                          # ├── 自然语言描述生成
│                          # ├── 图片质量预处理
│                          # ├── 描述文本格式化
│                          # └── 错误处理和重试
```

#### 辅助功能文件

```
├── learning_report.py     # 学习报告生成器
│                          # ├── 对话历史分析
│                          # ├── 知识点提取和总结
│                          # ├── 学习进度评估
│                          # ├── LaTeX报告生成
│                          # ├── 统计数据可视化
│                          # └── 个性化学习建议
│
├── quiz_generator.py      # 习题生成工具
│                          # ├── 智能题目生成算法
│                          # ├── 难度等级控制
│                          # ├── 题目类型多样化
│                          # ├── 答案验证和评分
│                          # ├── 学习反馈生成
│                          # └── 题目质量评估
│
├── run_streamlit.py       # Streamlit应用启动脚本
│                          # ├── 应用初始化配置
│                          # ├── 端口和参数设置
│                          # ├── 浏览器自动打开
│                          # ├── 环境检查和验证
│                          # ├── 错误日志记录
│                          # └── 优雅关闭处理
│
├── main.py                # 命令行交互界面
│                          # ├── 简单的CLI聊天界面
│                          # ├── 基础的问答交互
│                          # ├── 系统状态监控
│                          # ├── 快速测试和调试
│                          # └── 开发环境使用
```

#### 数据存储目录

```
├── data/                  # 原始课程资料存储
│                          # ├── NLP课程PPT和PDF
│                          # ├── 教学资料文档
│                          # ├── 实验数据和代码
│                          # └── 参考文献资料
│
├── vector_db/             # 向量数据库存储
│                          # ├── ChromaDB向量索引
│                          # ├── BM25稀疏检索索引
│                          # ├── 文档元数据存储
│                          # ├── 嵌入向量缓存
│                          # └── 检索性能优化
│
├── chat_history/          # 对话历史记录
│                          # ├── JSON格式对话存储
│                          # ├── 多对话会话管理
│                          # ├── 历史记录持久化
│                          # ├── 对话统计分析
│                          # └── 数据导出功能
```


## 🖼️ 图像识别

本项目现已支持**多模态文档处理**，可对文档中的图像信息进行提取、理解与融合。

1. **增强的 PDF/PPDX 解析（`document_loader.py`）**：
   * 原有的 PDF 解析器已替换为 **PyMuPDF（fitz）**，显著提升了文本与图像提取的成功率和准确性。
   * 支持从 PDF 与 PPTX 文件中提取图像，并统一保存至 `./images_extracted/` 目录中。

2. **图像文本化（`text_splitter.py`）**：
   * 在文档切分（chunking）流程之前，新增了图像预处理步骤。
   * `TextSplitter` 会调用 **`ImageProcessor`**（定义于 `image_processor.py`），将每一页 / 每一张幻灯片中提取的图像转换为描述性文本。
   * 生成的图像描述文本将被**追加**到原始文档文本内容中，使 RAG 检索在文本之外同时感知并利用视觉信息。


## 🌐 联网查询功能

一个简单的 toolcalling 架构，利用 tavily 的联网查询功能。


## 🔍 检索系统升级：混合检索与多轮增强

本次升级将原有的纯向量搜索（密集检索）架构，提升为智能混合检索（Hybrid Retrieval）系统，以应对复杂、多轮次以及包含专业术语的查询。

### 1. 复合检索策略：弥补纯向量搜索的不足

我们集成了稀疏检索 BM25 和 Reciprocal Rank Fusion（RRF）算法，实现了精准与语义的平衡：

* **密集检索（Dense Retrieval）：** 利用 ChromaDB 向量搜索，擅长理解抽象概念、定义和原理，处理**语义相关**的查询。
* **稀疏检索（BM25 Retrieval）：** 基于关键词的匹配，擅长处理包含罕见、专业、技术性名词或 ID 等的**字面匹配**查询。
* **混合检索（Hybrid Retrieval）：** **核心策略**。同时执行两种检索，并使用 RRF 算法智能融合并重新排序结果，确保兼顾语义和关键词的最佳准确性。

> **持久化优化：** 我们解决了 BM25 索引需要重建的性能问题，通过序列化工具（如 `joblib`）将其持久化到磁盘，确保系统启动时能够快速加载索引。


### 2. LLM 驱动的智能策略分派与决策

为了最大限度发挥复合检索的效能，我们让 LLM 动态选择最高效的检索策略：

* **策略分析：** 在执行检索前，系统调用 LLM（`_analyze_query_type`）分析用户的查询意图（概念主导、关键词主导或混合），并智能决策是采用纯 **DENSE**、纯 **BM25** 还是 **HYBRID** 策略。
* **动态分派：** 系统根据 LLM 的决策结果，自动分派到 `VectorStore` 中对应的搜索方法，避免了单一策略的局限性。

### 3. 多轮对话检索增强（指代消解）

针对多轮对话场景中常见的上下文指代问题，我们实现了 LLM 驱动的查询重写：

* **指代消解：** `RAGAgent`（在 `_construct_search_query` 中）将当前查询和最近的对话历史发送给 LLM。
* **查询提炼：** LLM 将模糊查询（如“它有什么缺点？”）提炼成一个**精确且独立**的、无指代关系的检索查询（如“Transformer 模型的缺点”），从根本上解决了多轮问答中的检索漂移问题，极大地提升了用户体验。



## 🚀 Streamlit 可视化界面

项目现在支持现代化的Web界面！使用Streamlit构建的交互式聊天界面。

### 运行可视化界面
```bash

python run_streamlit.py

```

### 界面功能
- 🖥️ **现代化Web界面**：直观的聊天界面替代命令行
- 📊 **系统状态监控**：实时显示知识库状态
- 💬 **对话历史持久化**：自动保存和恢复对话历史
- 📁 **多对话管理**：新建、切换、删除多个对话
- 🔄 **一键初始化**：简化系统启动流程
- 💾 **数据持久化**：对话数据保存到本地文件
- 🖼️ **图片智能问答**：支持在聊天中上传图片进行智能分析
- 📚 **动态知识库**：支持对话途中实时添加新文档和文本到知识库

### 使用步骤
1. 确保向量数据库已创建（运行 `python process_data.py`）
2. 启动Streamlit应用：`python run_streamlit.py`
3. 浏览器自动打开 `http://localhost:8501`
4. 点击侧边栏的"初始化系统"
5. 开始与AI助教对话！

### 图片问答功能
- 💬 **文本问答**：直接在聊天框输入问题
- 🖼️ **图片问答**：点击聊天框右侧的"图片"按钮上传图片，然后输入相关问题
- 🎯 **智能分析**：AI会先分析图片内容，再结合课程资料回答问题
- 📎 **附件显示**：消息中会显示是否包含图片附件
- 🔄 **自动清空**：发送消息后自动清空图片上传区域，避免重复发送
- ⚡ **即时刷新**：发送后立即重新渲染界面，确保上传区域完全清空
- 👁️ **实时预览**：上传图片后实时显示预览，无论是否输入了问题
- 📚 **历史图片**：对话历史中显示曾经上传的图片缩略图
- 🧠 **智能提示**：系统提示词已优化，明确说明图片输入处理方式

### 动态知识库功能
- 📤 **文档上传**：在对话中实时上传PDF、PPTX、DOCX、TXT文档
- 📝 **文本输入**：直接输入文本内容添加到知识库
- ⚡ **实时处理**：上传后立即处理并向量化，无需重启系统
- 📊 **状态更新**：实时显示知识库文档数量变化
- 🔄 **增量添加**：在原有知识基础上持续扩充，无需重建整个库

### 对话持久化功能

**自动保存机制：**
- 📝 **实时保存**：每条消息发送后自动保存
- 💾 **本地存储**：对话数据保存为JSON文件在 `./chat_history/` 目录
- 🔄 **自动恢复**：重新启动应用时可恢复历史对话
- 📁 **多对话支持**：支持同时管理多个独立对话

**对话管理：**
- ➕ **新建对话**：创建全新的对话会话
- 🗑️ **清空当前对话**：清空当前对话的消息历史
- 📝 **当前对话**：高亮显示正在进行的对话
- 📄 **历史对话**：浏览和切换到之前的对话（排除当前对话）
- 🗑️ **删除对话**：清理不需要的对话记录
- 📊 **对话统计**：显示每条对话的消息数量和时间

**数据结构：**
```json
{
  "id": "对话唯一ID",
  "title": "对话标题（自动生成）",
  "timestamp": "2024-12-12T10:30:00",
  "messages": [
    {"role": "user", "content": "用户消息"},
    {"role": "assistant", "content": "AI回答"}
  ]
}
```

### 界面预览
```
🎓 智能课程助教
├── 🔄 初始化系统按钮
├── 📊 系统状态显示
├── 💬 对话管理
│   ├── ➕ 新建对话
│   ├── 🗑️ 清空当前对话
│   ├── 📝 当前对话：[高亮显示]
│   ├── 📄 历史对话列表
│   └── 🗑️ 删除对话
├── 💬 对话界面
│   ├── 用户消息气泡
│   └── AI回答气泡
└── 📝 输入框
```

## 🛫 Quick Start

### 环境准备

```bash
pip install -r requirements.txt

# 3. 配置API密钥
# 编辑 config.py 文件，设置你的API密钥
OPENAI_API_KEY = "your-api-key"
TAVILY_API_KEY = "your-tavily-key"
```

### 数据准备

```bash
# 4. 处理课程资料（构建知识库）
python process_data.py

# 可选参数：
# --clear-cache    清理缓存重新处理
# --cache-info     查看缓存状态
```

### 启动应用

```bash
# 5. 启动Web界面
python run_streamlit.py

# 或者使用命令行界面
python main.py
```

### 使用说明

1. 浏览器访问 `http://localhost:8501`
2. 点击侧边栏"初始化系统"
3. 开始与智能助教对话！


## 配置说明

### API配置 (config.py)

```python
# OpenAI兼容接口
OPENAI_API_KEY = "your-api-key"
OPENAI_API_BASE = "https://dashscope.aliyuncs.com/compatible-mode/v1"

# 模型配置
MODEL_NAME = "qwen3-max"
OPENAI_EMBEDDING_MODEL = "text-embedding-v4"
OPENAI_VL_MODEL = "qwen3-vl-plus"
```

