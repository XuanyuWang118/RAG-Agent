# RAG-Agent

NLP Course Project [Info](https://gpy5q03kes.feishu.cn/wiki/JgqTwaqG2ih6hdkWk6pcYBhAnPd)

Members: XuanyuWang, RuiTao, BoruiZhang

### Git usage
```bash
git pull                # 拉取仓库
git status              # 查看修改状态
git add .               # 把修改加入暂存区
git commit -m "message" # 提交到 github 仓库
git push                # 上传
```

### Data
NLP Course PPts


### Chat Example
```
============================================================
欢迎使用智能课程助教系统！
============================================================

学生: 解释一下对于大语言模型ChatGPT为什么效果这么好？

助教: ChatGPT之所以效果出色，主要归因于以下几个关键因素：

1. **预训练使大模型储存了大量知识**：通过在海量文本数据上进行预训练，ChatGPT学习并内化了广泛的世界知识，为其后续任务表现奠定了基础。[来源：4.2 大语言模型 v2.pptx, 幻灯片 39]

2. **指令微调提升了泛化与对齐能力**：在预训练基础上，通过指令微调（Instruction Tuning），模型学会了更好地理解和遵循人类指令，从而在多样化的任务中展现出强大的泛化能力，并实现与人类意图的对齐。[来源：4.2 大语言模型 v2.pptx, 幻灯片 39 和 幻灯片 86]

3. **代码数据增强了复杂推理能力**：训练数据中包含大量编程代码，这使得模型能够学习到结构化、逻辑严密的推理模式。其中，面向过程的编程模拟人类逐步解决问题的方式，而面向对象的编程则帮助模型将复杂任务分解为多个简单子任务，从而提升其处理复杂问题的能力。[来源：4.2 大语言模型 v2.pptx, 幻灯片 39]

4. **模型规模的指数级增长带来性能跃升与“涌现”现象**：随着参数量和训练数据规模的大幅增加，模型不仅在常规任务上表现更优，还在某些高阶能力（如复杂推理）上出现“涌现”——即在规模突破某一阈值后，能力突然显著提升。[来源：4.2 大语言模型 v2.pptx, 幻灯片 4 和 幻灯片 86]

5. **更智能的交互体验与通用性**：ChatGPT支持自然、流畅的人机对话，并能适应多种任务场景（如问答、创作、推理等），这种通用性和人性化交互是其广受欢迎的重要原因。[来源：4.2 大语言模型 v2.pptx, 幻灯片 3]

综上，ChatGPT的成功是大规模预训练、高质量指令微调、多样化训练数据（包括代码）、模型规模效应以及人机对齐设计共同作用的结果。
```
```
学生: 解释一下双向自编码模型BERT的优缺点？

助教: 双向自编码模型 BERT 的优缺点如下：

**优点：**  
- 在自然语言理解（NLU）任务上表现突出。  
- 使用基于 Attention 的 Transformer Encoder 结构，能够有效建模双向上下文信息，克服了传统自回归模型难以捕捉双向语境的局限性。

**缺点：**  
- 难以解决自然语言生成（NLG）问题，因其采用掩蔽语言模型（MLM）进行预训练，不适合逐词生成任务。  
- 预训练和微调阶段的输入空间分布不匹配（例如，预训练中使用 [MASK] 标记，而微调时通常没有）。  
- 预训练过程收敛较慢，且不能掩蔽过多词元，否则会影响训练效率和效果。  
- 假设被掩蔽的词元之间是独立的，这导致对联合概率的估计是有偏的。例如，在句子 “New York is a city.” 中，若 “New” 和 “York” 同时被掩蔽，模型无法利用它们之间的依赖关系进行准确预测。

[来源：4.1 预训练语言模型.pptx, 幻灯片 41、42]
```
```
学生: 分析一下当前俄乌战争局势？

助教: 我无法根据当前课程材料回答这个问题，请参考相关教材或联系老师。
```

### 添加
一个简单的toolcalling架构。

利用tavily的联网查询功能。

稍微修改了一下提示词来使用tool。

## 🚀 Streamlit 可视化界面

项目现在支持现代化的Web界面！使用Streamlit构建的交互式聊天界面。

### 安装依赖
```bash
pip install -r requirements.txt
```

### 运行可视化界面
```bash

python run_streamlit.py

```

### 界面功能
- 🖥️ **现代化Web界面**：直观的聊天界面替代命令行
- 📊 **系统状态监控**：实时显示知识库状态
- 💬 **对话历史持久化**：自动保存和恢复对话历史
- 📁 **多对话管理**：新建、切换、删除多个对话
- 🔄 **一键初始化**：简化系统启动流程
- 💾 **数据持久化**：对话数据保存到本地文件
- 🖼️ **图片智能问答**：支持在聊天中上传图片进行智能分析
- 📚 **动态知识库**：支持对话途中实时添加新文档和文本到知识库

### 使用步骤
1. 确保向量数据库已创建（运行 `python process_data.py`）
2. 启动Streamlit应用：`python run_streamlit.py`
3. 浏览器自动打开 `http://localhost:8501`
4. 点击侧边栏的"初始化系统"
5. 开始与AI助教对话！

### 图片问答功能
- 💬 **文本问答**：直接在聊天框输入问题
- 🖼️ **图片问答**：点击聊天框右侧的"图片"按钮上传图片，然后输入相关问题
- 🎯 **智能分析**：AI会先分析图片内容，再结合课程资料回答问题
- 📎 **附件显示**：消息中会显示是否包含图片附件
- 🔄 **自动清空**：发送消息后自动清空图片上传区域，避免重复发送
- ⚡ **即时刷新**：发送后立即重新渲染界面，确保上传区域完全清空
- 👁️ **实时预览**：上传图片后实时显示预览，无论是否输入了问题
- 📚 **历史图片**：对话历史中显示曾经上传的图片缩略图
- 🧠 **智能提示**：系统提示词已优化，明确说明图片输入处理方式

### 动态知识库功能
- 📤 **文档上传**：在对话中实时上传PDF、PPTX、DOCX、TXT文档
- 📝 **文本输入**：直接输入文本内容添加到知识库
- ⚡ **实时处理**：上传后立即处理并向量化，无需重启系统
- 📊 **状态更新**：实时显示知识库文档数量变化
- 🔄 **增量添加**：在原有知识基础上持续扩充，无需重建整个库

### 对话持久化功能

**自动保存机制：**
- 📝 **实时保存**：每条消息发送后自动保存
- 💾 **本地存储**：对话数据保存为JSON文件在 `./chat_history/` 目录
- 🔄 **自动恢复**：重新启动应用时可恢复历史对话
- 📁 **多对话支持**：支持同时管理多个独立对话

**对话管理：**
- ➕ **新建对话**：创建全新的对话会话
- 🗑️ **清空当前对话**：清空当前对话的消息历史
- 📝 **当前对话**：高亮显示正在进行的对话
- 📄 **历史对话**：浏览和切换到之前的对话（排除当前对话）
- 🗑️ **删除对话**：清理不需要的对话记录
- 📊 **对话统计**：显示每条对话的消息数量和时间

**数据结构：**
```json
{
  "id": "对话唯一ID",
  "title": "对话标题（自动生成）",
  "timestamp": "2024-12-12T10:30:00",
  "messages": [
    {"role": "user", "content": "用户消息"},
    {"role": "assistant", "content": "AI回答"}
  ]
}
```

### 界面预览
```
🎓 智能课程助教
├── 🔄 初始化系统按钮
├── 📊 系统状态显示
├── 💬 对话管理
│   ├── ➕ 新建对话
│   ├── 🗑️ 清空当前对话
│   ├── 📝 当前对话：[高亮显示]
│   ├── 📄 历史对话列表
│   └── 🗑️ 删除对话
├── 💬 对话界面
│   ├── 用户消息气泡
│   └── AI回答气泡
└── 📝 输入框
```
